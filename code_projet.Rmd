---
title: "R Notebook"
output: html_notebook
---

```{r}
# Install and load the required package
if (!requireNamespace("quantmod", quietly = TRUE)) {
  install.packages("quantmod")
}
library(quantmod)

# Define the stock ticker symbol and date range
ticker <- "NVDA"
start_date <- "2020-01-01"
end_date <- "2024-12-31"

# Fetch the stock data from Yahoo Finance
nvidia_data <- getSymbols(ticker, src = "yahoo", from = start_date, to = end_date, auto.assign = FALSE)

# Display the first few rows of the data
head(nvidia_data)


nvidia_df <- data.frame(date = index(nvidia_data), coredata(nvidia_data))

head(nvidia_df)
```

1- Data Preprocessing: Clean and preprocess the data. This may involve handling missing values,converting
date strings to datetime objects, and normalizing the data if necessary.



```{r}

# Handle missing values by removing rows with NA values
nvidia_data <- na.omit(nvidia_data)

# Vérifier les valeurs manquantes pour chaque colonne
missing_values <- sapply(nvidia_df, function(x) sum(is.na(x)))

# Afficher le nombre de valeurs manquantes par colonne
print(missing_values)

```


```{r}
summary(nvidia_df[-1])
```


```{r}
# Installer et charger le package skimr

library(skimr)

# Résumé statistique
skim(nvidia_df)

```

```{r}
# Charger les bibliothèques nécessaires

library(dplyr)

# Convertir 'nvidia_data' en un data frame et ajouter une colonne pour l'année

nvidia_df$year <- format(as.Date(nvidia_df$date), "%Y")

# Résumer les données par année
annual_summary <- nvidia_df %>%
  group_by(year) %>%
  summarise(
    Open_avg = mean(NVDA.Open, na.rm = TRUE),
    High_avg = mean(NVDA.High, na.rm = TRUE),
    Low_avg = mean(NVDA.Low, na.rm = TRUE),
    Close_avg = mean(NVDA.Close, na.rm = TRUE),
    Volume_avg = mean(NVDA.Volume, na.rm = TRUE),
    Open_max = max(NVDA.Open, na.rm = TRUE),
    High_max = max(NVDA.High, na.rm = TRUE),
    Low_min = min(NVDA.Low, na.rm = TRUE),
    Close_sd = sd(NVDA.Close, na.rm = TRUE)
  )

# Afficher le résumé
print(annual_summary)

```


```{r}
# 2 - Exploratory Data Analysis (EDA)
# Plot the opening prices
par(mfrow = c(1, 1))
plot(nvidia_df$NVDA.Open,type="l", main = "Opening Prices of NVDA", ylab = "Price", xlab = "Date",col='blue')
grid()

```


```{r}
par(mfrow = c(1, 1))
# Plot the closing prices
plot(nvidia_df$NVDA.Close,type="l", main = "Closing Prices of NVDA", ylab = "Price", xlab = "Date",col='blue')
grid()


```


```{r}
# Plot the high prices
par(mfrow = c(1, 1))
plot(nvidia_df$NVDA.High,type="l", main = "High Prices of NVDA", ylab = "Price", xlab = "Date",col='blue')
grid()

```



```{r}

# Plot the low prices
par(mfrow = c(1, 1))
plot(nvidia_df$NVDA.Low,type="l", main = "Low Prices of NVDA", ylab = "Price", xlab = "Date",col='blue')
grid()
```


```{r}

# Installer et charger ggplot2 si nécessaire
library(ggplot2)
library(reshape2)  # Pour transformer les données

# Restructurer les données pour ggplot2
nvidia_long <- melt(nvidia_df, id.vars = "date", measure.vars = c("NVDA.Open", "NVDA.High", "NVDA.Low", "NVDA.Close"))

# Créer le graphique
ggplot(nvidia_long, aes(x = date, y = value, color = variable)) +
  geom_line() +
  labs(
    title = "Prix NVIDIA (Open, High, Low, Close) sur le temps",
    x = "Date",
    y = "Prix",
    color = "Type de Prix"
  ) +
  theme_minimal()

```


```{r}
# Plot the volume
par(mfrow = c(1, 1))
plot(nvidia_df$NVDA.Volume,type="l", main = "Volume of NVDA", ylab = "Volume", xlab = "Date",col='blue')
grid()
```

TESTONS LE MODELE ARIMA

```{r}
# Décomposition de la série temporelle

nvidia_ts <- ts(nvidia_df$NVDA.Close, frequency = 365)
decom <- decompose(nvidia_ts)  # Spécifiez la fréquence si connue (par exemple, journalière = 365)

# Affichage des graphiques de décomposition
plot(decom, col='blue')
grid()

```



```{r}
tendance<-decom$trend
plot.ts(tendance, col='blue')
grid()
```



```{r}
# Extraire la série sans tendance
detrended_series <- nvidia_ts - decom$trend

# Tracer la série sans tendance
plot(detrended_series, type = "l", col = "blue", lwd = 1,
     main = "Série sans tendance (Detrended Series)",
     xlab = "Temps", ylab = "Valeurs ajustées")
grid()
```



```{r}
nvidia_ts_dif<-diff(nvidia_ts)
plot.ts(nvidia_ts_dif, col='blue')
grid()
```



```{r}
acf(nvidia_ts_dif)
```



```{r}
pacf(nvidia_ts_dif)
```



```{r}
nvidia_ts_dif2<-diff(nvidia_ts_dif)
plot.ts(nvidia_ts_dif2, col='blue')
grid()
```



```{r}
acf(nvidia_ts_dif2)
```



```{r}
pacf(nvidia_ts_dif2)
```


 ajustement du modele aux données en difference premire
```{r}


p<-4
q<-4

AIC<-matrix(0,p,q)
BIC<-matrix(0,p,q)


for(i in 1:p){
  for(j in 1:q){
    model<-arima(nvidia_ts_dif,order = c((i-1),0,(j-1)))
    if (Box.test(model$residuals)$p.value>0.05){
      AIC[i,j]<-AIC(model)
      BIC[i,j]<-BIC(model)
    } else {
      AIC[i,j]<-1
      BIC[i,j]<-1
    }
      
    
  }
}


AIC

BIC
```


Le modele choisi un ARMA(3,3) d'apres l'AIC sur la serie en difference première
Le modele choisi un ARMA(1,1) d'apres le BIC sur la serie en difference première

par ailleurs, ARMA(3,3) a pour AIC 4876.180 et pour BIC 4917.265
par ailleurs, ARMA(1,1) a pour AIC 4886.115 et pour BIC 4906.657

Nous allons evoluer avec le ARMA(1,1)
ainsi notre modele est un ARIMA(1,1,1)



```{r}
# Ajustement du modèle ARIMA(1,1,1)
arima_model <- arima(nvidia_ts, order = c(1, 1, 1))

# Prévisions pour ajuster la série
fitted_values <- nvidia_ts - residuals(arima_model)  # Valeurs ajustées

# Tracé des séries
plot(nvidia_ts, type = "l", col = "blue", lwd = 1, 
     ylab = "Valeurs", xlab = "Temps", main = "Série d'origine et ajustée avec ARIMA(1,1,1)")
lines(fitted_values, col = "red", lwd = 1, lty = 1)

# Ajout d'une légende
legend("toplef", legend = c("Série d'origine", "Série ajustée"), 
       col = c("blue", "red"), lwd = 1, lty = c(1, 2))

```


```{r}
# Charger le package forecast (si nécessaire)
if (!require(forecast)) install.packages("forecast")
library(forecast)

# Prédictions pour les 10 prochaines périodes
forecast_arima <- forecast(arima_model, h = 10)

# Affichage des résultats des prédictions
print(forecast_arima)

# Tracé des prédictions
plot(forecast_arima, main = "Prédictions pour les 10 prochaines périodes avec ARIMA(1,1,1)",
     ylab = "Valeurs", xlab = "Temps")


```
 TESTONS LE MODELE GARCH
 
Dans cette partie il est question de choisir le meilleur modèle GARCH qui fit bien à nos données et de faire les prediction sur 10 périodes comme pour le modele ARIMA.

```{r}
NVDA = nvidia_data[, "NVDA.Close", drop=F]


```



```{r}
### 1.2. Analyses des séries de rendement 

# calculate log-returns for GARCH analysis
NVDA.ret = CalculateReturns(NVDA, method="log")


# remove first NA observation
NVDA.ret = NVDA.ret[-1,]

colnames(NVDA.ret) ="NVDA"

# plot returns
plot(NVDA.ret, col="blue")
```


```{r}

###1.1. Analyse des carrés des rendements et des autocorrélations

# plot returns with squared and absolute returns
par(mfrow=c(3,1))

plot(NVDA.ret, main="NVDA Returns")

plot(NVDA.ret^2, main="NVDA Returns^2")

plot(abs(NVDA.ret), main="NVDA abs(Returns)")

```


```{r}
# plot autocorrelations of returns, returns^2 and abs(returns)
par(mfrow=c(3,1))
acf(NVDA.ret, main="NVDA Returns")

acf(NVDA.ret^2, main="NVDA Returns^2")

acf(abs(NVDA.ret), main="NVDA abs(Returns)")
```



```{r}
par(mfrow=c(3,1))
pacf(NVDA.ret, main="NVDA Returns")

pacf(NVDA.ret^2, main="NVDA Returns^2")

pacf(abs(NVDA.ret), main="NVDA abs(Returns)")
```



```{r}

#1.4. Spécification et construction des modèles

# model selection on GARCH(p,q) models

# lois normale


# fit all arch models with 0 < p <= 4


library(data.table)

results_df1 <- data.table()

garch.order1 = 1:3
garch.order2 = 0:3

for (p in garch.order1) {
  for (q in garch.order2) {
    garch_spec <- ugarchspec(mean.model = list(armaOrder = c(0, 0)), 
                             variance.model = list(garchOrder = c(p, q), model = "sGARCH"),
                             distribution.model = "norm")
    garch_fit1 <- ugarchfit(spec = garch_spec, data = NVDA.ret)
    print(garch_fit1)
    info_criteria1 <- infocriteria(garch_fit1)
    results_df1 <- rbind(results_df1, list(p = p, q = q, aic =info_criteria1[1] ))
  }}

library(openxlsx)

write.xlsx(results_df1,"F:/valdes/school/3- ENSAI/Ecole/series temporelles/Projet serie temporelle", 
           sheetName = "aic NVDA", rowNames = FALSE)

```


```{r}

library(data.table)
library(rugarch)
library(openxlsx)

# Initialisation de la table des résultats
results_df1 <- data.table()

# Combinaisons d'ordres GARCH
garch.order1 <- 1:3
garch.order2 <- 0:3

# Parcours des ordres p et q
for (p in garch.order1) {
  for (q in garch.order2) {
    tryCatch({
      # Spécification du modèle GARCH
      garch_spec <- ugarchspec(
        mean.model = list(armaOrder = c(0, 0)), 
        variance.model = list(garchOrder = c(p, q), model = "sGARCH"),
        distribution.model = "norm"
      )
      
      # Ajustement du modèle
      garch_fit1 <- ugarchfit(spec = garch_spec, data = NVDA.ret)
      
      # Critères d'information
      info_criteria1 <- infocriteria(garch_fit1)
      
      # Ajout des résultats
      results_df1 <- rbind(
        results_df1, 
        list(p = p, q = q, aic = info_criteria1[1], bic = info_criteria1[2])
      )
    }, error = function(e) {
      # Enregistrement des modèles échoués
      results_df1 <- rbind(results_df1, list(p = p, q = q, aic = NA, bic = NA))
      message(sprintf("Erreur pour p=%d, q=%d : %s", p, q, e$message))
    })
  }
}

# Export des résultats vers un fichier Excel
write.xlsx(
  results_df1,
  file = "F:/valdes/school/3- ENSAI/Ecole/series temporelles/Projet serie temporelle/results_NVDA.xlsx",
  sheetName = "aic_bic NVDA", 
  rowNames = FALSE
)


```

```{r}
# Charger le package rugarch
if (!require(rugarch)) install.packages("rugarch")
library(rugarch)

# Paramètres maximum pour les ordres GARCH
P <- 5  # Maximum pour l'ordre ARCH (p)
Q <- 5  # Maximum pour l'ordre GARCH (q)

# Initialisation des matrices pour AIC et BIC
AIC_matrix <- matrix(NA, nrow = P, ncol = Q)
BIC_matrix <- matrix(NA, nrow = P, ncol = Q)

# Parcours des ordres (p, q)
for (p in 1:P) {
  for (q in 1:Q) {
    tryCatch({
      # Spécification du modèle GARCH
      garch_spec <- ugarchspec(
        variance.model = list(garchOrder = c(p - 1, q - 1), model = "sGARCH"),
        mean.model = list(armaOrder = c(0, 0), include.mean = TRUE),
        distribution.model = "norm"
      )
      
      # Ajustement du modèle GARCH
      garch_fit <- ugarchfit(spec = garch_spec, data = NVDA.ret)
      
      # Extraction des résidus standardisés
      residuals_std <- residuals(garch_fit, standardize = TRUE)
      
      # Test de Ljung-Box sur les résidus standardisés
      box_test <- Box.test(residuals_std, lag = 30, type = "Ljung-Box")
      
      if (box_test$p.value > 0.05) {
        # Si les résidus passent le test, enregistrer AIC et BIC
        info_criteria <- infocriteria(garch_fit)
        AIC_matrix[p, q] <- info_criteria["Akaike"]
        BIC_matrix[p, q] <- info_criteria["Bayes"]
      } else {
        # Modèle rejeté en raison des résidus autocorrélés
        AIC_matrix[p, q] <- -1
        BIC_matrix[p, q] <- -1
      }
    }, error = function(e) {
      # Gestion des erreurs (modèle non convergent)
      AIC_matrix[p, q] <- NA
      BIC_matrix[p, q] <- NA
      message(sprintf("Erreur pour p=%d, q=%d : %s", p - 1, q - 1, e$message))
    })
  }
}

# Afficher les matrices AIC et BIC
print("Matrice AIC :")
print(AIC_matrix)

print("Matrice BIC :")
print(BIC_matrix)

```


```{r}
# Paramètres maximum pour les ordres GARCH
P <- 5  # Maximum pour l'ordre ARCH (p)
Q <- 5  # Maximum pour l'ordre GARCH (q)

# Initialisation des matrices pour AIC et BIC
AIC_matrix <- matrix(NA, nrow = P, ncol = Q)
BIC_matrix <- matrix(NA, nrow = P, ncol = Q)

# Parcours des ordres (p, q)
for (p in 1:P) {
  for (q in 1:Q) {
    tryCatch({
      # Spécification du modèle GARCH
      garch_spec <- ugarchspec(
        variance.model = list(garchOrder = c(p - 1, q - 1), model = "sGARCH"),
        mean.model = list(armaOrder = c(0, 0), include.mean = TRUE),
        distribution.model = "std"
      )
      
      # Ajustement du modèle GARCH
      garch_fit <- ugarchfit(spec = garch_spec, data = NVDA.ret)
      
      # Extraction des résidus standardisés
      residuals_std <- residuals(garch_fit, standardize = TRUE)
      
      # Test de Ljung-Box sur les résidus standardisés
      box_test <- Box.test(residuals_std, lag = 30, type = "Ljung-Box")
      
      if (box_test$p.value > 0.05) {
        # Si les résidus passent le test, enregistrer AIC et BIC
        info_criteria <- infocriteria(garch_fit)
        AIC_matrix[p, q] <- info_criteria["Akaike"]
        BIC_matrix[p, q] <- info_criteria["Bayes"]
      } else {
        # Modèle rejeté en raison des résidus autocorrélés
        AIC_matrix[p, q] <- -1
        BIC_matrix[p, q] <- -1
      }
    }, error = function(e) {
      # Gestion des erreurs (modèle non convergent)
      AIC_matrix[p, q] <- NA
      BIC_matrix[p, q] <- NA
      message(sprintf("Erreur pour p=%d, q=%d : %s", p - 1, q - 1, e$message))
    })
  }
}

# Afficher les matrices AIC et BIC
print("Matrice AIC :")
print(AIC_matrix)

print("Matrice BIC :")
print(BIC_matrix)

```


```{r}

```



```{r}

```














